import * as i0 from "@angular/core";
export declare type TranscoderConfig = {
    sampleRate: number;
};
export declare type TranscodeParams = TranscoderConfig & {
    blob: Blob;
};
declare type WriteWaveHeaderParams = {
    arrayBuffer: ArrayBuffer;
    channelCount: number;
    sampleRate: number;
};
declare type WriteAudioDataParams = {
    arrayBuffer: ArrayBuffer;
    dataByChannel: Float32Array[];
};
/**
 * The `TranscoderService` is used to transcibe audio recording to a format that's supported by all major browsers. The SDK uses this to create voice messages.
 *
 * If you want to use your own transcoder you can provide a `customTranscoder`.
 */
export declare class TranscoderService {
    config: TranscoderConfig;
    customTranscoder?: (blob: Blob) => Blob | Promise<Blob>;
    constructor();
    /**
     * The default transcoder will leave audio/mp4 files as is, and transcode webm files to wav. If you want to customize this, you can provide your own transcoder using the `customTranscoder` field
     * @param blob
     * @returns the transcoded file
     */
    transcode(blob: Blob): Promise<Blob>;
    protected renderAudio(audioBuffer: AudioBuffer, sampleRate: number): Promise<AudioBuffer>;
    protected toAudioBuffer(blob: Blob): Promise<AudioBuffer>;
    protected writeWavAudioData({ arrayBuffer, dataByChannel, }: WriteAudioDataParams): void;
    protected writeWavHeader({ arrayBuffer, channelCount, sampleRate, }: WriteWaveHeaderParams): void;
    protected splitDataByChannel: (audioBuffer: AudioBuffer) => Float32Array[];
    static ɵfac: i0.ɵɵFactoryDeclaration<TranscoderService, never>;
    static ɵprov: i0.ɵɵInjectableDeclaration<TranscoderService>;
}
export {};
